{
  "best_global_step": 2200,
  "best_metric": 1.101335048675537,
  "best_model_checkpoint": "./mixtral_qlora_out/checkpoint-2200",
  "epoch": 1.397712833545108,
  "eval_steps": 200,
  "global_step": 2200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.012706480304955527,
      "grad_norm": 2.775622606277466,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 3.2968,
      "step": 20
    },
    {
      "epoch": 0.025412960609911054,
      "grad_norm": 4.9246416091918945,
      "learning_rate": 3.3e-05,
      "loss": 2.8382,
      "step": 40
    },
    {
      "epoch": 0.03811944091486658,
      "grad_norm": 1.3045260906219482,
      "learning_rate": 5.300000000000001e-05,
      "loss": 2.0146,
      "step": 60
    },
    {
      "epoch": 0.05082592121982211,
      "grad_norm": 1.5132052898406982,
      "learning_rate": 7.3e-05,
      "loss": 1.5522,
      "step": 80
    },
    {
      "epoch": 0.06353240152477764,
      "grad_norm": 0.9262126684188843,
      "learning_rate": 9.300000000000001e-05,
      "loss": 1.3368,
      "step": 100
    },
    {
      "epoch": 0.07623888182973317,
      "grad_norm": 1.0570374727249146,
      "learning_rate": 9.971873647771528e-05,
      "loss": 1.3706,
      "step": 120
    },
    {
      "epoch": 0.08894536213468869,
      "grad_norm": 0.7736604809761047,
      "learning_rate": 9.928602336650801e-05,
      "loss": 1.2999,
      "step": 140
    },
    {
      "epoch": 0.10165184243964422,
      "grad_norm": 0.7886855602264404,
      "learning_rate": 9.885331025530074e-05,
      "loss": 1.3353,
      "step": 160
    },
    {
      "epoch": 0.11435832274459974,
      "grad_norm": 0.9733624458312988,
      "learning_rate": 9.842059714409347e-05,
      "loss": 1.3097,
      "step": 180
    },
    {
      "epoch": 0.12706480304955528,
      "grad_norm": 0.6799979209899902,
      "learning_rate": 9.79878840328862e-05,
      "loss": 1.2214,
      "step": 200
    },
    {
      "epoch": 0.12706480304955528,
      "eval_loss": 1.1985507011413574,
      "eval_runtime": 1034.5218,
      "eval_samples_per_second": 1.353,
      "eval_steps_per_second": 0.169,
      "step": 200
    },
    {
      "epoch": 0.1397712833545108,
      "grad_norm": 0.8642019629478455,
      "learning_rate": 9.755517092167893e-05,
      "loss": 1.271,
      "step": 220
    },
    {
      "epoch": 0.15247776365946633,
      "grad_norm": 0.8778282999992371,
      "learning_rate": 9.712245781047166e-05,
      "loss": 1.2682,
      "step": 240
    },
    {
      "epoch": 0.16518424396442186,
      "grad_norm": 0.7638278603553772,
      "learning_rate": 9.66897446992644e-05,
      "loss": 1.2243,
      "step": 260
    },
    {
      "epoch": 0.17789072426937738,
      "grad_norm": 0.7554725408554077,
      "learning_rate": 9.625703158805712e-05,
      "loss": 1.2099,
      "step": 280
    },
    {
      "epoch": 0.1905972045743329,
      "grad_norm": 0.860641598701477,
      "learning_rate": 9.582431847684985e-05,
      "loss": 1.2096,
      "step": 300
    },
    {
      "epoch": 0.20330368487928843,
      "grad_norm": 0.7062935829162598,
      "learning_rate": 9.539160536564259e-05,
      "loss": 1.2021,
      "step": 320
    },
    {
      "epoch": 0.21601016518424396,
      "grad_norm": 0.658734142780304,
      "learning_rate": 9.495889225443532e-05,
      "loss": 1.1932,
      "step": 340
    },
    {
      "epoch": 0.22871664548919948,
      "grad_norm": 0.9209176301956177,
      "learning_rate": 9.452617914322804e-05,
      "loss": 1.2059,
      "step": 360
    },
    {
      "epoch": 0.241423125794155,
      "grad_norm": 0.7557951211929321,
      "learning_rate": 9.409346603202078e-05,
      "loss": 1.1862,
      "step": 380
    },
    {
      "epoch": 0.25412960609911056,
      "grad_norm": 0.822695255279541,
      "learning_rate": 9.366075292081351e-05,
      "loss": 1.1948,
      "step": 400
    },
    {
      "epoch": 0.25412960609911056,
      "eval_loss": 1.1647099256515503,
      "eval_runtime": 1034.4875,
      "eval_samples_per_second": 1.353,
      "eval_steps_per_second": 0.169,
      "step": 400
    },
    {
      "epoch": 0.2668360864040661,
      "grad_norm": 0.8225364089012146,
      "learning_rate": 9.322803980960624e-05,
      "loss": 1.2897,
      "step": 420
    },
    {
      "epoch": 0.2795425667090216,
      "grad_norm": 0.7565651535987854,
      "learning_rate": 9.279532669839896e-05,
      "loss": 1.2116,
      "step": 440
    },
    {
      "epoch": 0.29224904701397714,
      "grad_norm": 0.8448898792266846,
      "learning_rate": 9.23626135871917e-05,
      "loss": 1.1656,
      "step": 460
    },
    {
      "epoch": 0.30495552731893266,
      "grad_norm": 0.6319584250450134,
      "learning_rate": 9.192990047598443e-05,
      "loss": 1.1739,
      "step": 480
    },
    {
      "epoch": 0.3176620076238882,
      "grad_norm": 0.7455640435218811,
      "learning_rate": 9.149718736477716e-05,
      "loss": 1.1476,
      "step": 500
    },
    {
      "epoch": 0.3303684879288437,
      "grad_norm": 0.6679955124855042,
      "learning_rate": 9.106447425356988e-05,
      "loss": 1.2609,
      "step": 520
    },
    {
      "epoch": 0.34307496823379924,
      "grad_norm": 0.8159177303314209,
      "learning_rate": 9.063176114236262e-05,
      "loss": 1.1827,
      "step": 540
    },
    {
      "epoch": 0.35578144853875476,
      "grad_norm": 0.7352922558784485,
      "learning_rate": 9.019904803115536e-05,
      "loss": 1.1561,
      "step": 560
    },
    {
      "epoch": 0.3684879288437103,
      "grad_norm": 1.0878019332885742,
      "learning_rate": 8.976633491994808e-05,
      "loss": 1.1851,
      "step": 580
    },
    {
      "epoch": 0.3811944091486658,
      "grad_norm": 0.6887272000312805,
      "learning_rate": 8.93336218087408e-05,
      "loss": 1.1614,
      "step": 600
    },
    {
      "epoch": 0.3811944091486658,
      "eval_loss": 1.1494872570037842,
      "eval_runtime": 1032.9132,
      "eval_samples_per_second": 1.355,
      "eval_steps_per_second": 0.169,
      "step": 600
    },
    {
      "epoch": 0.39390088945362134,
      "grad_norm": 0.7002314329147339,
      "learning_rate": 8.890090869753354e-05,
      "loss": 1.1636,
      "step": 620
    },
    {
      "epoch": 0.40660736975857686,
      "grad_norm": 0.8147837519645691,
      "learning_rate": 8.846819558632628e-05,
      "loss": 1.1391,
      "step": 640
    },
    {
      "epoch": 0.4193138500635324,
      "grad_norm": 0.8378369212150574,
      "learning_rate": 8.8035482475119e-05,
      "loss": 1.2005,
      "step": 660
    },
    {
      "epoch": 0.4320203303684879,
      "grad_norm": 0.8038415908813477,
      "learning_rate": 8.760276936391172e-05,
      "loss": 1.1623,
      "step": 680
    },
    {
      "epoch": 0.44472681067344344,
      "grad_norm": 0.7229872941970825,
      "learning_rate": 8.717005625270446e-05,
      "loss": 1.1422,
      "step": 700
    },
    {
      "epoch": 0.45743329097839897,
      "grad_norm": 0.9046448469161987,
      "learning_rate": 8.67373431414972e-05,
      "loss": 1.164,
      "step": 720
    },
    {
      "epoch": 0.4701397712833545,
      "grad_norm": 0.9368040561676025,
      "learning_rate": 8.630463003028992e-05,
      "loss": 1.2067,
      "step": 740
    },
    {
      "epoch": 0.48284625158831,
      "grad_norm": 0.8945390582084656,
      "learning_rate": 8.587191691908264e-05,
      "loss": 1.1804,
      "step": 760
    },
    {
      "epoch": 0.49555273189326554,
      "grad_norm": 0.9320871233940125,
      "learning_rate": 8.543920380787538e-05,
      "loss": 1.1678,
      "step": 780
    },
    {
      "epoch": 0.5082592121982211,
      "grad_norm": 0.7611891031265259,
      "learning_rate": 8.500649069666812e-05,
      "loss": 1.1592,
      "step": 800
    },
    {
      "epoch": 0.5082592121982211,
      "eval_loss": 1.1388612985610962,
      "eval_runtime": 1033.8161,
      "eval_samples_per_second": 1.354,
      "eval_steps_per_second": 0.169,
      "step": 800
    },
    {
      "epoch": 0.5209656925031766,
      "grad_norm": 0.803706169128418,
      "learning_rate": 8.457377758546084e-05,
      "loss": 1.1722,
      "step": 820
    },
    {
      "epoch": 0.5336721728081322,
      "grad_norm": 0.7567920088768005,
      "learning_rate": 8.414106447425358e-05,
      "loss": 1.1559,
      "step": 840
    },
    {
      "epoch": 0.5463786531130876,
      "grad_norm": 1.0187668800354004,
      "learning_rate": 8.37083513630463e-05,
      "loss": 1.142,
      "step": 860
    },
    {
      "epoch": 0.5590851334180432,
      "grad_norm": 0.7346451282501221,
      "learning_rate": 8.327563825183904e-05,
      "loss": 1.1495,
      "step": 880
    },
    {
      "epoch": 0.5717916137229987,
      "grad_norm": 0.6688073873519897,
      "learning_rate": 8.284292514063176e-05,
      "loss": 1.1746,
      "step": 900
    },
    {
      "epoch": 0.5844980940279543,
      "grad_norm": 0.8464875221252441,
      "learning_rate": 8.24102120294245e-05,
      "loss": 1.1304,
      "step": 920
    },
    {
      "epoch": 0.5972045743329097,
      "grad_norm": 0.820885956287384,
      "learning_rate": 8.197749891821722e-05,
      "loss": 1.1776,
      "step": 940
    },
    {
      "epoch": 0.6099110546378653,
      "grad_norm": 0.730622410774231,
      "learning_rate": 8.154478580700996e-05,
      "loss": 1.172,
      "step": 960
    },
    {
      "epoch": 0.6226175349428208,
      "grad_norm": 0.7860458493232727,
      "learning_rate": 8.111207269580268e-05,
      "loss": 1.156,
      "step": 980
    },
    {
      "epoch": 0.6353240152477764,
      "grad_norm": 1.00807785987854,
      "learning_rate": 8.067935958459542e-05,
      "loss": 1.1335,
      "step": 1000
    },
    {
      "epoch": 0.6353240152477764,
      "eval_loss": 1.1304845809936523,
      "eval_runtime": 1036.8759,
      "eval_samples_per_second": 1.35,
      "eval_steps_per_second": 0.169,
      "step": 1000
    },
    {
      "epoch": 0.6480304955527318,
      "grad_norm": 0.8480648994445801,
      "learning_rate": 8.024664647338814e-05,
      "loss": 1.2074,
      "step": 1020
    },
    {
      "epoch": 0.6607369758576874,
      "grad_norm": 0.6640006899833679,
      "learning_rate": 7.981393336218088e-05,
      "loss": 1.1878,
      "step": 1040
    },
    {
      "epoch": 0.6734434561626429,
      "grad_norm": 0.746004045009613,
      "learning_rate": 7.93812202509736e-05,
      "loss": 1.152,
      "step": 1060
    },
    {
      "epoch": 0.6861499364675985,
      "grad_norm": 0.9270418882369995,
      "learning_rate": 7.894850713976634e-05,
      "loss": 1.1096,
      "step": 1080
    },
    {
      "epoch": 0.6988564167725541,
      "grad_norm": 0.8590976595878601,
      "learning_rate": 7.851579402855907e-05,
      "loss": 1.1434,
      "step": 1100
    },
    {
      "epoch": 0.7115628970775095,
      "grad_norm": 1.1155263185501099,
      "learning_rate": 7.80830809173518e-05,
      "loss": 1.146,
      "step": 1120
    },
    {
      "epoch": 0.7242693773824651,
      "grad_norm": 0.922967255115509,
      "learning_rate": 7.765036780614453e-05,
      "loss": 1.1447,
      "step": 1140
    },
    {
      "epoch": 0.7369758576874206,
      "grad_norm": 0.8902442455291748,
      "learning_rate": 7.721765469493726e-05,
      "loss": 1.1877,
      "step": 1160
    },
    {
      "epoch": 0.7496823379923762,
      "grad_norm": 0.89478999376297,
      "learning_rate": 7.678494158372999e-05,
      "loss": 1.1744,
      "step": 1180
    },
    {
      "epoch": 0.7623888182973316,
      "grad_norm": 0.791180431842804,
      "learning_rate": 7.635222847252272e-05,
      "loss": 1.1574,
      "step": 1200
    },
    {
      "epoch": 0.7623888182973316,
      "eval_loss": 1.1242800951004028,
      "eval_runtime": 1036.4082,
      "eval_samples_per_second": 1.351,
      "eval_steps_per_second": 0.169,
      "step": 1200
    },
    {
      "epoch": 0.7750952986022872,
      "grad_norm": 0.8883368968963623,
      "learning_rate": 7.591951536131545e-05,
      "loss": 1.1521,
      "step": 1220
    },
    {
      "epoch": 0.7878017789072427,
      "grad_norm": 0.8379299640655518,
      "learning_rate": 7.548680225010818e-05,
      "loss": 1.1884,
      "step": 1240
    },
    {
      "epoch": 0.8005082592121983,
      "grad_norm": 0.8405075073242188,
      "learning_rate": 7.505408913890091e-05,
      "loss": 1.096,
      "step": 1260
    },
    {
      "epoch": 0.8132147395171537,
      "grad_norm": 0.806458592414856,
      "learning_rate": 7.462137602769365e-05,
      "loss": 1.1647,
      "step": 1280
    },
    {
      "epoch": 0.8259212198221093,
      "grad_norm": 0.8790041208267212,
      "learning_rate": 7.418866291648637e-05,
      "loss": 1.1596,
      "step": 1300
    },
    {
      "epoch": 0.8386277001270648,
      "grad_norm": 0.8293303847312927,
      "learning_rate": 7.37559498052791e-05,
      "loss": 1.1149,
      "step": 1320
    },
    {
      "epoch": 0.8513341804320204,
      "grad_norm": 0.8816559910774231,
      "learning_rate": 7.332323669407183e-05,
      "loss": 1.1185,
      "step": 1340
    },
    {
      "epoch": 0.8640406607369758,
      "grad_norm": 0.9306995272636414,
      "learning_rate": 7.289052358286457e-05,
      "loss": 1.1225,
      "step": 1360
    },
    {
      "epoch": 0.8767471410419314,
      "grad_norm": 0.9499005675315857,
      "learning_rate": 7.245781047165729e-05,
      "loss": 1.1707,
      "step": 1380
    },
    {
      "epoch": 0.8894536213468869,
      "grad_norm": 0.7085556387901306,
      "learning_rate": 7.202509736045003e-05,
      "loss": 1.1029,
      "step": 1400
    },
    {
      "epoch": 0.8894536213468869,
      "eval_loss": 1.1188966035842896,
      "eval_runtime": 1033.3781,
      "eval_samples_per_second": 1.355,
      "eval_steps_per_second": 0.169,
      "step": 1400
    },
    {
      "epoch": 0.9021601016518425,
      "grad_norm": 0.9464632868766785,
      "learning_rate": 7.159238424924276e-05,
      "loss": 1.1894,
      "step": 1420
    },
    {
      "epoch": 0.9148665819567979,
      "grad_norm": 0.9920024871826172,
      "learning_rate": 7.115967113803549e-05,
      "loss": 1.1481,
      "step": 1440
    },
    {
      "epoch": 0.9275730622617535,
      "grad_norm": 0.735241174697876,
      "learning_rate": 7.072695802682821e-05,
      "loss": 1.1484,
      "step": 1460
    },
    {
      "epoch": 0.940279542566709,
      "grad_norm": 0.9840216040611267,
      "learning_rate": 7.029424491562095e-05,
      "loss": 1.189,
      "step": 1480
    },
    {
      "epoch": 0.9529860228716646,
      "grad_norm": 0.772390604019165,
      "learning_rate": 6.986153180441368e-05,
      "loss": 1.1487,
      "step": 1500
    },
    {
      "epoch": 0.96569250317662,
      "grad_norm": 0.9990763068199158,
      "learning_rate": 6.942881869320641e-05,
      "loss": 1.1361,
      "step": 1520
    },
    {
      "epoch": 0.9783989834815756,
      "grad_norm": 0.9236243963241577,
      "learning_rate": 6.899610558199913e-05,
      "loss": 1.121,
      "step": 1540
    },
    {
      "epoch": 0.9911054637865311,
      "grad_norm": 0.8741818070411682,
      "learning_rate": 6.856339247079187e-05,
      "loss": 1.1204,
      "step": 1560
    },
    {
      "epoch": 1.0038119440914866,
      "grad_norm": 0.7819377183914185,
      "learning_rate": 6.81306793595846e-05,
      "loss": 1.1284,
      "step": 1580
    },
    {
      "epoch": 1.0165184243964422,
      "grad_norm": 0.8436205983161926,
      "learning_rate": 6.769796624837733e-05,
      "loss": 1.1203,
      "step": 1600
    },
    {
      "epoch": 1.0165184243964422,
      "eval_loss": 1.1136099100112915,
      "eval_runtime": 1037.3065,
      "eval_samples_per_second": 1.35,
      "eval_steps_per_second": 0.169,
      "step": 1600
    },
    {
      "epoch": 1.0292249047013977,
      "grad_norm": 0.9637439846992493,
      "learning_rate": 6.726525313717005e-05,
      "loss": 1.1288,
      "step": 1620
    },
    {
      "epoch": 1.0419313850063532,
      "grad_norm": 1.322038173675537,
      "learning_rate": 6.683254002596279e-05,
      "loss": 1.122,
      "step": 1640
    },
    {
      "epoch": 1.0546378653113089,
      "grad_norm": 0.7089045643806458,
      "learning_rate": 6.639982691475553e-05,
      "loss": 1.1172,
      "step": 1660
    },
    {
      "epoch": 1.0673443456162643,
      "grad_norm": 0.9454559087753296,
      "learning_rate": 6.596711380354825e-05,
      "loss": 1.1193,
      "step": 1680
    },
    {
      "epoch": 1.0800508259212198,
      "grad_norm": 1.010284662246704,
      "learning_rate": 6.553440069234097e-05,
      "loss": 1.1365,
      "step": 1700
    },
    {
      "epoch": 1.0927573062261753,
      "grad_norm": 0.9303988814353943,
      "learning_rate": 6.510168758113371e-05,
      "loss": 1.1303,
      "step": 1720
    },
    {
      "epoch": 1.105463786531131,
      "grad_norm": 1.03789484500885,
      "learning_rate": 6.466897446992645e-05,
      "loss": 1.1027,
      "step": 1740
    },
    {
      "epoch": 1.1181702668360864,
      "grad_norm": 1.1913037300109863,
      "learning_rate": 6.423626135871917e-05,
      "loss": 1.1261,
      "step": 1760
    },
    {
      "epoch": 1.130876747141042,
      "grad_norm": 0.8912292122840881,
      "learning_rate": 6.38035482475119e-05,
      "loss": 1.0767,
      "step": 1780
    },
    {
      "epoch": 1.1435832274459974,
      "grad_norm": 1.0286871194839478,
      "learning_rate": 6.337083513630463e-05,
      "loss": 1.1291,
      "step": 1800
    },
    {
      "epoch": 1.1435832274459974,
      "eval_loss": 1.110177993774414,
      "eval_runtime": 1035.216,
      "eval_samples_per_second": 1.352,
      "eval_steps_per_second": 0.169,
      "step": 1800
    },
    {
      "epoch": 1.156289707750953,
      "grad_norm": 0.8522087931632996,
      "learning_rate": 6.293812202509737e-05,
      "loss": 1.1836,
      "step": 1820
    },
    {
      "epoch": 1.1689961880559085,
      "grad_norm": 0.9908900260925293,
      "learning_rate": 6.250540891389009e-05,
      "loss": 1.0869,
      "step": 1840
    },
    {
      "epoch": 1.181702668360864,
      "grad_norm": 1.2999364137649536,
      "learning_rate": 6.207269580268283e-05,
      "loss": 1.1607,
      "step": 1860
    },
    {
      "epoch": 1.1944091486658195,
      "grad_norm": 1.1741422414779663,
      "learning_rate": 6.163998269147555e-05,
      "loss": 1.1346,
      "step": 1880
    },
    {
      "epoch": 1.2071156289707752,
      "grad_norm": 0.853140652179718,
      "learning_rate": 6.120726958026829e-05,
      "loss": 1.106,
      "step": 1900
    },
    {
      "epoch": 1.2198221092757306,
      "grad_norm": 0.9902237057685852,
      "learning_rate": 6.0774556469061014e-05,
      "loss": 1.0985,
      "step": 1920
    },
    {
      "epoch": 1.2325285895806861,
      "grad_norm": 1.101879596710205,
      "learning_rate": 6.0341843357853744e-05,
      "loss": 1.1134,
      "step": 1940
    },
    {
      "epoch": 1.2452350698856416,
      "grad_norm": 0.9256738424301147,
      "learning_rate": 5.9909130246646474e-05,
      "loss": 1.1114,
      "step": 1960
    },
    {
      "epoch": 1.2579415501905973,
      "grad_norm": 0.9837455153465271,
      "learning_rate": 5.947641713543921e-05,
      "loss": 1.1435,
      "step": 1980
    },
    {
      "epoch": 1.2706480304955527,
      "grad_norm": 0.9668142795562744,
      "learning_rate": 5.904370402423194e-05,
      "loss": 1.0593,
      "step": 2000
    },
    {
      "epoch": 1.2706480304955527,
      "eval_loss": 1.1055210828781128,
      "eval_runtime": 1035.062,
      "eval_samples_per_second": 1.353,
      "eval_steps_per_second": 0.169,
      "step": 2000
    },
    {
      "epoch": 1.2833545108005082,
      "grad_norm": 1.0271035432815552,
      "learning_rate": 5.863262656858504e-05,
      "loss": 1.1556,
      "step": 2020
    },
    {
      "epoch": 1.2960609911054637,
      "grad_norm": 1.0054501295089722,
      "learning_rate": 5.819991345737776e-05,
      "loss": 1.0987,
      "step": 2040
    },
    {
      "epoch": 1.3087674714104194,
      "grad_norm": 0.9716946482658386,
      "learning_rate": 5.776720034617049e-05,
      "loss": 1.0829,
      "step": 2060
    },
    {
      "epoch": 1.3214739517153749,
      "grad_norm": 1.08494234085083,
      "learning_rate": 5.733448723496322e-05,
      "loss": 1.109,
      "step": 2080
    },
    {
      "epoch": 1.3341804320203303,
      "grad_norm": 1.1907668113708496,
      "learning_rate": 5.690177412375596e-05,
      "loss": 1.1482,
      "step": 2100
    },
    {
      "epoch": 1.346886912325286,
      "grad_norm": 1.116278052330017,
      "learning_rate": 5.646906101254868e-05,
      "loss": 1.1145,
      "step": 2120
    },
    {
      "epoch": 1.3595933926302415,
      "grad_norm": 1.029730200767517,
      "learning_rate": 5.603634790134141e-05,
      "loss": 1.0915,
      "step": 2140
    },
    {
      "epoch": 1.372299872935197,
      "grad_norm": 0.9998635053634644,
      "learning_rate": 5.560363479013414e-05,
      "loss": 1.098,
      "step": 2160
    },
    {
      "epoch": 1.3850063532401524,
      "grad_norm": 1.1446645259857178,
      "learning_rate": 5.517092167892688e-05,
      "loss": 1.1173,
      "step": 2180
    },
    {
      "epoch": 1.397712833545108,
      "grad_norm": 1.2096863985061646,
      "learning_rate": 5.4738208567719604e-05,
      "loss": 1.1276,
      "step": 2200
    },
    {
      "epoch": 1.397712833545108,
      "eval_loss": 1.101335048675537,
      "eval_runtime": 1033.2841,
      "eval_samples_per_second": 1.355,
      "eval_steps_per_second": 0.169,
      "step": 2200
    }
  ],
  "logging_steps": 20,
  "max_steps": 4722,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.0145494333954458e+19,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
